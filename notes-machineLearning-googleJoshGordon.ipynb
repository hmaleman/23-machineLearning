{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Recipes\n",
    "\n",
    "## 0. General info\n",
    "- Course: Machine Leaning Recipes\n",
    "- Channel: Youtube\n",
    "- Written by: Josh Gordon \n",
    "- Course [link](https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Pipeline\n",
    "\"Learning is the process of using training data to adjust the parameters \n",
    "of the model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 0.946666666667\n",
      "KNeighborsClassifier: 0.946666666667\n"
     ]
    }
   ],
   "source": [
    "# import iris dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Classifier as f(x) = y\n",
    "X = iris.data   # features\n",
    "y = iris.target  # labels\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Randomly split the given dataset in half - train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)\n",
    "\n",
    "\n",
    "def fitAndScore(classifier):\n",
    "    my_classifier.fit(X_train, y_train)\n",
    "    # Predict labels from the test set\n",
    "    predictions = my_classifier.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    # Measure the classifier score based on the predictions vs the known labels\n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "from sklearn import tree\n",
    "my_classifier = tree.DecisionTreeClassifier()\n",
    "print(\"DecisionTreeClassifier:\", fitAndScore(my_classifier))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "my_classifier = KNeighborsClassifier()\n",
    "print(\"KNeighborsClassifier:\", fitAndScore(my_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow playground**: Change and adjust parameters to observe a Neural Network learn [link](http://goo.gl/cv7Dq5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Writing a Classifier\n",
    "The following classifier is *based* on the k-Nearest Neighbors algorithm. In this algorithm the classifier predicts an input based on the distance to the k Nearest points. \n",
    "\n",
    "For a 2D distance example (dataset with 2 features categories), the Euclidean distance is calculated: `distance = sqrt((X2-X1)² + (Y2-Y1)²)`\n",
    "\n",
    "The Euclidean distance works the same way, regardless on the size of the dimensions, hence: `distance = sqrt((X2-X1)² + (Y2-Y1)² + ... + (N2-N1)²)`\n",
    "\n",
    "Pros and Cons on this algorithm:\n",
    "- Pros: It's a relatively simple algorithm\n",
    "- Cons: Computationally intensive, since for each prediction it's necessary to iterate through the whole training dataset. Additionally it's hard to represent relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "#import random\n",
    "\n",
    "def euc(a,b):\n",
    "    return distance.euclidean(a,b)\n",
    "\n",
    "# Basic classifier based on k-Nearest Neighbors\n",
    "class ScrappyKNN():\n",
    "    # Minimal methods for a classifier: fit, predict \n",
    "    # fit requires the features and label sets (paremeters)\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    # predict requires the features test set - outputs the predicted labels\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for row in X_test:\n",
    "            #label = random.choice(self.y_train)\n",
    "            label = self.closest(row)\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "    \n",
    "    def closest(self, row):\n",
    "        closest_dist = euc(row, self.X_train[0])\n",
    "        closest_index = 0\n",
    "        for i in range(1, len(self.X_train)):\n",
    "            dist = euc(row, self.X_train[i])\n",
    "            if dist < closest_dist:\n",
    "                closest_dist = dist\n",
    "                closest_index = i\n",
    "        return self.y_train[closest_index]\n",
    "\n",
    "# import iris dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Classifier as f(x) = y\n",
    "X = iris.data   # features\n",
    "y = iris.target  # labels\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Randomly split the given dataset in half - train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)\n",
    "\n",
    "my_classifier = ScrappyKNN()\n",
    "my_classifier.fit(X_train, y_train)\n",
    "predictions = my_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Measure the classifier score based on the predictions vs the known labels\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Classifier with TensorFlow\n",
    "TensorFlow Codelab. In this codelab we retrain (aka transfer learning) an existing image classifier, Inception. It was trained on 1.2 million images and is open source. Retraining in this example takes 20 min vs 2 weeeks of the initial training on a computer with 8 GPUs.\n",
    "\n",
    "**Keys to train a good classifier are diversity (different image types from one label) and quantity of images**.\n",
    "\n",
    "This lab uses TensorFlow for Poets which is a library for TensorFlow, similar to sklearn (fit, predict ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Image Classifier with TF.Learn\n",
    "Based on an TensorFlow image on Docker, the episode shows the process of: Installation, Download dataset, Visualize images, Train a classifier, Evaluate the accuracy and finally how to Visualize the weights graphically."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
